{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sDIGARmvpsYa"},"outputs":[],"source":["# Import PyDrive and associated libraries.\n","# This only needs to be done once per notebook.\n","import logging\n","logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39826,"status":"ok","timestamp":1695523346106,"user":{"displayName":"Sarim K","userId":"14069573488697398739"},"user_tz":300},"id":"NIjXjZriOO4O","outputId":"23d35058-b6e4-48e7-cf8c-b0e324a6c2cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Copying gs://tibot-ml-labeling/datasets/cats_vs_dogs_dataset.zip...\n","/ [0/1 files][    0.0 B/593.6 MiB]   0% Done                                    \r==> NOTE: You are downloading one or more large file(s), which would\n","run significantly faster if you enabled sliced object downloads. This\n","feature is enabled by default but requires that compiled crcmod be\n","installed (see \"gsutil help crcmod\").\n","\n","|\n","Operation completed over 1 objects/593.6 MiB.                                    \n"]}],"source":["!gsutil -m cp gs://tibot-ml-labeling/datasets/cats_vs_dogs_dataset.zip  ./"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X5o4aMNLLwCY"},"outputs":[],"source":["!unzip -q /content/cats_vs_dogs_dataset.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vV_FtjHwL_92"},"outputs":[],"source":["import os\n","import torch\n","import timm\n","import poutyne\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from sklearn.metrics import classification_report, confusion_matrix\n","import wandb\n","from poutyne.framework import Model, Callback\n","from google.cloud import storage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-UuZMnK98L5"},"outputs":[],"source":["# Check if a GPU is available and use it, otherwise use CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TrG_2CrbpVaP"},"outputs":[],"source":["# Define the directory path\n","model_dir = '/content/models'\n","\n","# Check if the directory exists, and create it if it doesn't\n","if not os.path.exists(model_dir):\n","    os.makedirs(model_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysDEqlQMMZwi"},"outputs":[],"source":["#  Define dataset paths\n","train_dir = '/content/dataset/train'\n","test_dir = '/content/dataset/test'\n","\n","# Define data transformations\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# Create custom datasets\n","train_dataset = ImageFolder(train_dir, transform=data_transforms['train'])\n","test_dataset = ImageFolder(test_dir, transform=data_transforms['test'])\n","\n","# Create data loaders\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EE57vEASNVbn"},"outputs":[],"source":["# Define your model\n","model_name = 'tf_efficientnetv2_b2'\n","num_classes = 2  # Number of classes (cats and dogs)\n","\n","# Load the model architecture and move it to the GPU\n","model = timm.create_model(model_name, pretrained=False, num_classes=num_classes).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1695437467799,"user":{"displayName":"Sarim K","userId":"14069573488697398739"},"user_tz":300},"id":"PAVVyGFfcUFv","outputId":"d9531098-178a-44c6-dfd3-cac4eaf52400"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]},{"data":{"text/plain":["True"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Log in with your WANDB API key\n","wandb.login(key=\"1adf1a1fccd0e0da79c739f91daa90e0da69abb7\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ql3-7P-kZI1x"},"outputs":[],"source":["class UploadModelCallback(poutyne.Callback):\n","    def __init__(self, bucket_name, remote_dir, num_epochs=1):\n","        super().__init__()\n","        self.num_epochs = num_epochs\n","        self.bucket_name = bucket_name\n","        self.remote_dir = remote_dir\n","        self.local_dir = \"/content/models\"\n","\n","        self.storage_client = storage.Client()\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if (epoch + 1) >= 1:  # Upload the model checkpoint after each epoch\n","            # Save the model checkpoint locally\n","            checkpoint_path = os.path.join(self.local_dir, f\"EfficientNetV2B2_checkpoint-{epoch + 1:02d}.ckpt\")\n","            self.model.save_weights(checkpoint_path)\n","\n","            # Upload the model checkpoint to Google Cloud Storage\n","            remote_filepath = os.path.join(self.remote_dir, os.path.basename(checkpoint_path))\n","            bucket = self.storage_client.bucket(self.bucket_name)\n","            blob = bucket.blob(remote_filepath)\n","            blob.upload_from_filename(checkpoint_path)\n","\n","            print(f\"Model checkpoint saved in {checkpoint_path} and uploaded to {remote_filepath}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519,"referenced_widgets":["8f6d13988ae44408a97e8b4680525d34","d51711e346564dafa2011ba0df7e29dd","47408166f1b14be69a8ba29792d21486","e0f0147bc5384630bbad79c344467220","6b6be007c40a4fabbaae7e8b1e6dfed1","f599a889799740a79c548c7aa43dc22d","1145c50983e94f969b44b0aedbd6ee6c","cac3c19526e94f2c88fbb6943a44ba60"]},"executionInfo":{"elapsed":8075,"status":"ok","timestamp":1695439500450,"user":{"displayName":"Sarim K","userId":"14069573488697398739"},"user_tz":300},"id":"Ggqn4eXxXFp-","outputId":"8b7a79a5-cc2c-42a0-aca4-cf0a78e70e95"},"outputs":[{"data":{"text/html":["Finishing last run (ID:3nwfqpzo) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f6d13988ae44408a97e8b4680525d34","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▅▆█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>██▅▃▁</td></tr><tr><td>time</td><td>▃█▃▁▄</td></tr><tr><td>val_acc</td><td>▅▇▁█▄</td></tr><tr><td>val_loss</td><td>▂█▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>71.78432</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.59261</td></tr><tr><td>time</td><td>186.194</td></tr><tr><td>val_acc</td><td>73.30938</td></tr><tr><td>val_loss</td><td>0.6842</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">lyric-wave-5</strong> at: <a href='https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch/runs/3nwfqpzo' target=\"_blank\">https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch/runs/3nwfqpzo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230923_025115-3nwfqpzo/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:3nwfqpzo). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.11"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230923_032454-a8fmgw7d</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch/runs/a8fmgw7d' target=\"_blank\">morning-jazz-6</a></strong> to <a href='https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch' target=\"_blank\">https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch/runs/a8fmgw7d' target=\"_blank\">https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch/runs/a8fmgw7d</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/polyfins-internship23-us/cats-vs-dogs-pytorch/runs/a8fmgw7d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7faa1c60fdc0>"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize wandb\n","wandb.init(project=\"cats-vs-dogs-pytorch\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AC09tz5SgCjP"},"outputs":[],"source":["# Define WandbCallback\n","class WandbCallback(poutyne.Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        # Log metrics to Wandb\n","        wandb.log(logs, step=epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RrVEaCV-Sfef"},"outputs":[],"source":["# Define loss function and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1942114,"status":"ok","timestamp":1695441499454,"user":{"displayName":"Sarim K","userId":"14069573488697398739"},"user_tz":300},"id":"0qacvH0EUoqM","outputId":"403f9030-24f4-4f37-fc17-14aa5d987591"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch:  1/10 Train steps: 563 Val steps: 148 3m7.53s loss: 0.820910 acc: 64.330183 val_loss: 1.019648 val_acc: 61.094675\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-02.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-02.pth\n","Epoch:  2/10 Train steps: 563 Val steps: 148 3m8.77s loss: 0.678666 acc: 67.409672 val_loss: 0.831540 val_acc: 70.667794\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-03.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-03.pth\n","Epoch:  3/10 Train steps: 563 Val steps: 148 3m8.64s loss: 0.663032 acc: 68.221234 val_loss: 0.823749 val_acc: 71.428571\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-04.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-04.pth\n","Epoch:  4/10 Train steps: 563 Val steps: 148 3m8.77s loss: 0.631708 acc: 70.111173 val_loss: 0.740841 val_acc: 77.049873\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-05.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-05.pth\n","Epoch:  5/10 Train steps: 563 Val steps: 148 3m8.78s loss: 0.597654 acc: 71.145081 val_loss: 0.702964 val_acc: 76.690617\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-06.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-06.pth\n","Epoch:  6/10 Train steps: 563 Val steps: 148 3m9.05s loss: 0.591759 acc: 71.612007 val_loss: 0.644878 val_acc: 76.986475\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-07.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-07.pth\n","Epoch:  7/10 Train steps: 563 Val steps: 148 3m8.95s loss: 0.578458 acc: 72.645914 val_loss: 0.909935 val_acc: 75.316991\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-08.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-08.pth\n","Epoch:  8/10 Train steps: 563 Val steps: 148 3m8.31s loss: 0.567992 acc: 72.896053 val_loss: 0.536283 val_acc: 80.494506\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-09.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-09.pth\n","Epoch:  9/10 Train steps: 563 Val steps: 148 3m8.30s loss: 0.550587 acc: 74.252362 val_loss: 0.558002 val_acc: 80.853762\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-10.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-10.pth\n","Epoch: 10/10 Train steps: 563 Val steps: 148 3m8.06s loss: 0.535226 acc: 75.453029 val_loss: 0.520585 val_acc: 80.431107\n","Model checkpoint saved in /content/models/EfficientNetV2B2_checkpoint-11.pth and uploaded to models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model/EfficientNetV2B2_checkpoint-11.pth\n"]},{"data":{"text/plain":["[{'epoch': 1,\n","  'time': 187.52506872499998,\n","  'loss': 0.8209104235070225,\n","  'acc': 64.33018343693817,\n","  'val_loss': 1.0196481143783334,\n","  'val_acc': 61.09467456266221},\n"," {'epoch': 2,\n","  'time': 188.77442567399976,\n","  'loss': 0.6786655789749565,\n","  'acc': 67.4096720417186,\n","  'val_loss': 0.8315402082941438,\n","  'val_acc': 70.66779375116602},\n"," {'epoch': 3,\n","  'time': 188.63840757499975,\n","  'loss': 0.6630319650998839,\n","  'acc': 68.22123402059576,\n","  'val_loss': 0.8237494278639328,\n","  'val_acc': 71.42857144791901},\n"," {'epoch': 4,\n","  'time': 188.76890195299984,\n","  'loss': 0.6317076041557314,\n","  'acc': 70.11117287381879,\n","  'val_loss': 0.7408406508240978,\n","  'val_acc': 77.04987320371936},\n"," {'epoch': 5,\n","  'time': 188.7787981880001,\n","  'loss': 0.5976541504851972,\n","  'acc': 71.1450806011817,\n","  'val_loss': 0.7029640029419909,\n","  'val_acc': 76.69061707523245},\n"," {'epoch': 6,\n","  'time': 189.050871679,\n","  'loss': 0.5917591204671081,\n","  'acc': 71.61200667206879,\n","  'val_loss': 0.644877823852223,\n","  'val_acc': 76.98647507629653},\n"," {'epoch': 7,\n","  'time': 188.95222397700036,\n","  'loss': 0.5784581032575933,\n","  'acc': 72.64591439688716,\n","  'val_loss': 0.9099349884390328,\n","  'val_acc': 75.31699072095367},\n"," {'epoch': 8,\n","  'time': 188.31303899999966,\n","  'loss': 0.5679921674257917,\n","  'acc': 72.89605336128307,\n","  'val_loss': 0.5362827172746925,\n","  'val_acc': 80.49450551385307},\n"," {'epoch': 9,\n","  'time': 188.29549967599996,\n","  'loss': 0.5505867480701576,\n","  'acc': 74.25236242526502,\n","  'val_loss': 0.5580015043686329,\n","  'val_acc': 80.85376161009401},\n"," {'epoch': 10,\n","  'time': 188.06430762799937,\n","  'loss': 0.5352263787940451,\n","  'acc': 75.4530294591152,\n","  'val_loss': 0.5205849949475173,\n","  'val_acc': 80.43110734773508}]"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# Create the Poutyne Model\n","poutyne_model = Model(model, optimizer, criterion, batch_metrics=['accuracy']).to(device)\n","\n","# Train the model with upload callback\n","num_epochs = 10\n","bucket_name = \"tibot-ml-labeling\"\n","remote_dir = \"models/cats_vs_dogs_task/sarim/EfficientNetV2B2_Not_pretrained_/model\"\n","\n","# Define the upload callback\n","upload_callback = UploadModelCallback(bucket_name, remote_dir, num_epochs)\n","\n","# Modify the callbacks list to include the WandbCallback\n","callbacks = [upload_callback, WandbCallback()]\n","\n","# Train the model with the updated callbacks list\n","poutyne_model.fit_generator(train_loader, test_loader, epochs=num_epochs, callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26378,"status":"ok","timestamp":1695442526952,"user":{"displayName":"Sarim K","userId":"14069573488697398739"},"user_tz":300},"id":"OD9sF7SaU2ny","outputId":"1e840715-494d-4838-b61d-4de6555a5884"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test steps: 148 26.33s test_loss: 0.520585 test_acc: 80.431107                                \n","Test Accuracy: 80.43%\n"]}],"source":["# Calculate and print test accuracy\n","_, test_accuracy = poutyne_model.evaluate_generator(test_loader)\n","print(f\"Test Accuracy: {test_accuracy * 1:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25808,"status":"ok","timestamp":1695442563044,"user":{"displayName":"Sarim K","userId":"14069573488697398739"},"user_tz":300},"id":"pe7qFfdyV8sU","outputId":"f286d3e5-6818-4ce1-9411-dc2304623d8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","        cats       0.91      0.81      0.86      3505\n","        dogs       0.59      0.78      0.67      1227\n","\n","    accuracy                           0.80      4732\n","   macro avg       0.75      0.80      0.77      4732\n","weighted avg       0.83      0.80      0.81      4732\n","\n","\n","Confusion Matrix:\n","[[2851  654]\n"," [ 272  955]]\n"]}],"source":["import numpy as np\n","import torch\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","# Initialize lists to store predictions and true labels\n","true_labels = []\n","predicted_labels = []\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","# Move the model to the same device as the input data\n","model = model.to(device)\n","\n","# Initialize lists to store predictions and true labels\n","true_labels = []\n","predicted_labels = []\n","\n","# Iterate over the test dataset and collect predictions and true labels\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Get predicted class (the class with the highest probability)\n","        predicted = outputs.argmax(axis=1)\n","\n","        true_labels.extend(labels.cpu().numpy())\n","        predicted_labels.extend(predicted.cpu().numpy())\n","\n","# Calculate and print the classification report\n","class_names = train_dataset.classes\n","classification_rep = classification_report(true_labels, predicted_labels, target_names=class_names)\n","print(\"Classification Report:\")\n","print(classification_rep)\n","\n","# Calculate and print the confusion matrix\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3856,"status":"ok","timestamp":1695445392247,"user":{"displayName":"Sarim K","userId":"14069573488697398739"},"user_tz":300},"id":"hVkrvmDv9CLL","outputId":"cec3879b-ca40-4fbc-9105-cd6556244447"},"outputs":[{"name":"stdout","output_type":"stream","text":["============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"]}],"source":["import torch.onnx\n","import torchvision.models as models\n","\n","# Load your PyTorch model\n","model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","input_data = torch.randn(1, 3, 224, 224)  # Adjust the shape as per your model's input\n","onnx_path = \"model.onnx\"\n","\n","# Export the PyTorch model to ONNX format\n","torch.onnx.export(model, input_data, onnx_path, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"R2fAEYmHbKZs","outputId":"c0895ba5-c36f-41ae-e9ae-f6564921d3e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n","Colab is still running...\n"]}],"source":["import time\n","\n","while True:\n","    print(\"Colab is still running...\")\n","    time.sleep(60)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":5,"status":"error","timestamp":1695266456129,"user":{"displayName":"Sarim K","userId":"14069573488697398739"},"user_tz":300},"id":"6JBC7b3N-p2R","outputId":"7f0317ab-4ca3-4f2d-e65e-476f291b3c6f"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-23aecc6e7c97>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    input_data =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["# tunnel vpn\n","# run on fast vpn\n","\n","\n","import onnxruntime as ort\n","import numpy as np\n","\n","# Load the ONNX model\n","onnx_model = ort.InferenceSession(onnx_path, providers=providers)\n","\n","# Provide input data (change this according to your model's input)\n","input_data =\n","# Run inference\n","output = onnx_model.run(None, input_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqVSDEjbwTAs"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPC5CcSOwfZdo8LNE3O5SeU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1145c50983e94f969b44b0aedbd6ee6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47408166f1b14be69a8ba29792d21486":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1145c50983e94f969b44b0aedbd6ee6c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cac3c19526e94f2c88fbb6943a44ba60","value":1}},"6b6be007c40a4fabbaae7e8b1e6dfed1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f6d13988ae44408a97e8b4680525d34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_d51711e346564dafa2011ba0df7e29dd","IPY_MODEL_47408166f1b14be69a8ba29792d21486"],"layout":"IPY_MODEL_e0f0147bc5384630bbad79c344467220"}},"cac3c19526e94f2c88fbb6943a44ba60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d51711e346564dafa2011ba0df7e29dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b6be007c40a4fabbaae7e8b1e6dfed1","placeholder":"​","style":"IPY_MODEL_f599a889799740a79c548c7aa43dc22d","value":"0.013 MB of 0.013 MB uploaded (0.000 MB deduped)\r"}},"e0f0147bc5384630bbad79c344467220":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f599a889799740a79c548c7aa43dc22d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}